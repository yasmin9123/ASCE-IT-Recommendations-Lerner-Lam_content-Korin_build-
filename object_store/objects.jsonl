{"id":"P1","doc_id":"asce_ai_readiness_memo_2025-12-20","object_type":"parent","title":"1. Executive Summary","text":"Section 1 frames a strategy for ASCE to serve as the authoritative steward of civil-engineering intelligence in the AI era. It proposes a profession-wide Intelligence Token ecosystem combining identity/ethics binding (Soulbound Tokens) with governed knowledge objects (Intelligence Tokens). The goal is for agentic AI systems to retrieve civil-engineering guidance in an attributable, auditable, context-aware manner consistent with the ASCE Code of Ethics, while supporting transparent attribution and possible compensation for original sources and ASCE stewardship.","metadata":{"section":"1","type":"section_parent","authority":"ASCE_memo"}}
{"id":"C1_1","doc_id":"asce_ai_readiness_memo_2025-12-20","object_type":"child","parent_id":"P1","title":"Core objective of the memo","text":"The memo’s objective is to position ASCE as the authoritative steward of civil-engineering intelligence for AI systems by governing how engineering guidance is packaged, retrieved, attributed, and audited. It recommends an Intelligence Token ecosystem so that AI retrieves governed guidance (not raw text) with provenance, applicability constraints, and ethical alignment.","metadata":{"section":"1","type":"key_claim","authority":"ASCE_memo"}}
{"id":"C1_2","doc_id":"asce_ai_readiness_memo_2025-12-20","object_type":"child","parent_id":"P1","title":"Two-token model summary (SBTs + ITs)","text":"The memo proposes two complementary token types: Soulbound Tokens (SBTs) bind professional identity, licensure context, and ethical responsibility to specific actors; Intelligence Tokens (ITs) represent authoritative civil-engineering knowledge objects with embedded provenance, applicability constraints, rights, and machine-readable metadata. Together they support accountable AI-mediated use of engineering guidance.","metadata":{"section":"1","type":"definition_summary","authority":"ASCE_memo"}}

{"id":"P2","doc_id":"asce_ai_readiness_memo_2025-12-20","object_type":"parent","title":"2. Structural Risks of AI to Civil Engineering Practice","text":"Section 2 lists structural risks when AI influences planning, design, and policy in a safety-critical, licensed profession. It emphasizes that risks go beyond basic data provenance and directly affect duty of care, public trust, and defensibility of decisions. The memo highlights risks like lost attribution/accountability, context stripping, silent drift of standards, blurred authority, lack of auditability, and erosion of professional credit and value.","metadata":{"section":"2","type":"section_parent","authority":"ASCE_memo"}}
{"id":"C2_1","doc_id":"asce_ai_readiness_memo_2025-12-20","object_type":"child","parent_id":"P2","title":"Risk: loss of attribution and accountability","text":"Structural risk: AI outputs can detach guidance from its original source and responsible professionals, undermining attribution and professional accountability. In civil engineering this creates legal and ethical exposure because responsibility chains become unclear.","metadata":{"section":"2","type":"risk","risk_id":"1","authority":"ASCE_memo"}}
{"id":"C2_2","doc_id":"asce_ai_readiness_memo_2025-12-20","object_type":"child","parent_id":"P2","title":"Risk: context stripping and misapplication","text":"Structural risk: AI can remove engineering guidance from the context and constraints that make it valid, leading to misapplication of judgment, incorrect scope, or unsafe reuse outside intended conditions.","metadata":{"section":"2","type":"risk","risk_id":"2","authority":"ASCE_memo"}}
{"id":"C2_3","doc_id":"asce_ai_readiness_memo_2025-12-20","object_type":"child","parent_id":"P2","title":"Risk: silent drift of standards","text":"Structural risk: AI-mediated workflows can create silent drift in codes, standards, and best practices if models or retrieval corpora change without clear versioning, supersession signals, or governance, weakening reliability over time.","metadata":{"section":"2","type":"risk","risk_id":"3","authority":"ASCE_memo"}}
{"id":"C2_4","doc_id":"asce_ai_readiness_memo_2025-12-20","object_type":"child","parent_id":"P2","title":"Risk: blurring authoritative vs advisory guidance","text":"Structural risk: AI can blur the boundary between authoritative requirements (e.g., codes/standards) and advisory material (e.g., commentary, educational text), increasing the chance users treat non-authoritative outputs as binding guidance.","metadata":{"section":"2","type":"risk","risk_id":"4","authority":"ASCE_memo"}}
{"id":"C2_5","doc_id":"asce_ai_readiness_memo_2025-12-20","object_type":"child","parent_id":"P2","title":"Risk: inability to audit AI-supported decisions","text":"Structural risk: Without retrieval governance and logging, it may be difficult to audit what sources an AI used, what version of guidance was applied, and whether constraints were respected—reducing defensibility in agency, judicial, and public contexts.","metadata":{"section":"2","type":"risk","risk_id":"5","authority":"ASCE_memo"}}
{"id":"C2_6","doc_id":"asce_ai_readiness_memo_2025-12-20","object_type":"child","parent_id":"P2","title":"Risk: erosion of professional credit and value","text":"Structural risk: When AI systems reuse engineering knowledge without clear attribution and rights controls, professional credit and economic value can erode for authors, editors, committees, and institutions that steward and validate the knowledge.","metadata":{"section":"2","type":"risk","risk_id":"6","authority":"ASCE_memo"}}

{"id":"P3","doc_id":"asce_ai_readiness_memo_2025-12-20","object_type":"parent","title":"3. Why ASCE Is the Natural Steward","text":"Section 3 argues ASCE is uniquely positioned to govern AI-era civil-engineering intelligence because it combines standards authority, ethical governance, institutional neutrality, and cross-sector trust. It notes ASCE already performs stewardship functions—curation, validation, version control, peer/committee review, and dissemination—across standards, publications, and education, and that tokenization extends these existing functions into AI-readable form.","metadata":{"section":"3","type":"section_parent","authority":"ASCE_memo"}}
{"id":"C3_1","doc_id":"asce_ai_readiness_memo_2025-12-20","object_type":"child","parent_id":"P3","title":"ASCE legitimacy vs vendors/platforms","text":"ASCE’s legitimacy comes from professional stewardship and public-interest mission, unlike vendors or single publishers. This makes ASCE a credible governance body for authoritative civil-engineering guidance used by AI systems.","metadata":{"section":"3","type":"key_claim","authority":"ASCE_memo"}}
{"id":"C3_2","doc_id":"asce_ai_readiness_memo_2025-12-20","object_type":"child","parent_id":"P3","title":"Existing stewardship functions that map to AI governance","text":"ASCE already provides AI-relevant stewardship functions: curation and validation of guidance, version control and supersession, peer/committee review processes, and broad dissemination across codes/standards, journals, books, guidance documents, and education. Tokenization is presented as continuity of these functions, not a new mission.","metadata":{"section":"3","type":"stewardship_functions","authority":"ASCE_memo"}}

{"id":"P4","doc_id":"asce_ai_readiness_memo_2025-12-20","object_type":"parent","title":"4. Intelligence Tokens and Soulbound Tokens","text":"Section 4 defines Intelligence Tokens as governed, AI-readable knowledge objects that represent authoritative civil-engineering content with embedded provenance, applicability constraints, rights, and machine-readable metadata. It defines Soulbound Tokens as non-transferable identity tokens that bind professional identity, licensure context, organizational role, and ethical responsibility to individuals or institutional actors. The section also describes ASCE’s role as compiler/steward while preserving attribution (and potentially compensation) for original sources.","metadata":{"section":"4","type":"section_parent","authority":"ASCE_memo"}}
{"id":"C4_1","doc_id":"asce_ai_readiness_memo_2025-12-20","object_type":"child","parent_id":"P4","title":"Definition: Intelligence Tokens (ITs)","text":"Intelligence Tokens (ITs) are governed, AI-readable knowledge objects representing authoritative civil-engineering content. Each token includes machine-readable metadata such as provenance, applicability constraints, rights, and authority signals so AI systems can retrieve and apply guidance appropriately and audibly.","metadata":{"section":"4","type":"definition","term":"Intelligence Tokens","authority":"ASCE_memo"}}
{"id":"C4_2","doc_id":"asce_ai_readiness_memo_2025-12-20","object_type":"child","parent_id":"P4","title":"Definition: Soulbound Tokens (SBTs)","text":"Soulbound Tokens (SBTs) are non-transferable tokens that bind professional identity and responsibility to a specific person or institutional actor. In this framework they encode licensure context, organizational role, and ethical responsibility so accountability is machine-readable in AI-mediated workflows.","metadata":{"section":"4","type":"definition","term":"Soulbound Tokens","authority":"ASCE_memo"}}
{"id":"C4_3","doc_id":"asce_ai_readiness_memo_2025-12-20","object_type":"child","parent_id":"P4","title":"Compiler vs original sources model","text":"The framework distinguishes ASCE’s compiler/steward role from the original sources. ASCE curates, validates, assigns authority, and governs reuse of collective works, while attribution (and where policy adopts it, compensation) is preserved for original authors, editors, reviewers, and committees.","metadata":{"section":"4","type":"governance_model","authority":"ASCE_memo"}}
{"id":"C4_F1","doc_id":"asce_ai_readiness_memo_2025-12-20","object_type":"child","parent_id":"P4","title":"Figure 1 — ASCE Intelligence Token Taxonomy","text":"This diagram presents the ASCE Intelligence Token Taxonomy, separating governance into two token classes under ASCE stewardship. Soulbound Tokens (SBTs) are non-transferable identity tokens binding professional identity, licensure, and ethical responsibility to individuals or institutional actors (examples shown include ASCE members and committee chairs). Intelligence Tokens (ITs) are governed, transferable knowledge assets representing authoritative civil-engineering content, including codes and standards, journals and books, and educational materials. The diagram identifies ASCE as the compiler and institutional steward responsible for curation, validation, authority assignment, and governance of reuse, while recognizing original sources (authors, editors, committees) with attribution and compensation preserved. The taxonomy shows how identity binding plus governed knowledge objects support ethical responsibility, attribution, and auditability in AI-mediated use.","metadata":{"section":"4","type":"figure_desc","figure":"1","has_image":true,"image_path":"assets/figure1.png","authority":"ASCE_memo"}}

{"id":"P5","doc_id":"asce_ai_readiness_memo_2025-12-20","object_type":"parent","title":"5. ASCE Object Store and Vector Store Architecture","text":"Section 5 proposes ASCE operate a canonical object store of authoritative, versioned Intelligence Tokens (and applicable Soulbound identity tokens) and a derived vector store for AI access. The vector store contains semantic embeddings derived only from ASCE-governed tokens. The intent is controlled semantic retrieval with preserved attribution, context, authority signals, and accountability constraints.","metadata":{"section":"5","type":"section_parent","authority":"ASCE_memo"}}
{"id":"C5_1","doc_id":"asce_ai_readiness_memo_2025-12-20","object_type":"child","parent_id":"P5","title":"Object store vs vector store (roles)","text":"The architecture separates a canonical object store (authoritative, versioned Intelligence Tokens and identity tokens) from a derived vector store (semantic embeddings). The object store is the source of truth; the vector store is optimized for semantic retrieval but remains derived from governed objects.","metadata":{"section":"5","type":"architecture","authority":"ASCE_memo"}}
{"id":"C5_2","doc_id":"asce_ai_readiness_memo_2025-12-20","object_type":"child","parent_id":"P5","title":"Governed embeddings and retrieval interfaces","text":"A key control is that embeddings are generated under ASCE governance and the vector store contains embeddings derived only from ASCE-governed tokens. Agentic AI systems access the vector store through governed retrieval interfaces rather than ingesting raw documents, enabling attribution, contextual integrity, and accountability.","metadata":{"section":"5","type":"governed_retrieval","authority":"ASCE_memo"}}
{"id":"C5_F2","doc_id":"asce_ai_readiness_memo_2025-12-20","object_type":"child","parent_id":"P5","title":"Figure 2 — Object Store → Vector Store → Agentic AI Flow","text":"This diagram shows a governed pipeline from ASCE’s canonical object store to a derived vector store and then to agentic AI systems. The ASCE Object Store contains Intelligence Tokens (ITs) and Soulbound Tokens (SBTs) as canonical, versioned objects compiled and governed by ASCE. Embedding generation occurs under ASCE control, producing semantic embeddings and related authority/context vectors that populate the ASCE Vector Store; the vector store is explicitly derived only from ITs. Agentic AI systems (e.g., planning and design agents, policy analysis agents, decision-support systems) do not ingest raw documents directly; they access the vector store only through governed retrieval interfaces, producing attributable outputs. The purpose is to enforce controlled AI access that preserves attribution, contextual integrity, and professional accountability.","metadata":{"section":"5","type":"figure_desc","figure":"2","has_image":true,"image_path":"assets/figure2.png","authority":"ASCE_memo"}}

{"id":"P6","doc_id":"asce_ai_readiness_memo_2025-12-20","object_type":"parent","title":"6. Alignment with the ASCE Code of Ethics","text":"Section 6 argues the Intelligence Token framework operationalizes ASCE ethical principles by making public-safety constraints, authority levels, truthfulness signals, and responsibility chains machine-readable and auditable. It maps this to practical supports: public welfare via applicability constraints, truthfulness via provenance/versioning, faithful agency via identity binding/accountability, and professional integrity via attribution and transparent reuse.","metadata":{"section":"6","type":"section_parent","authority":"ASCE_memo"}}
{"id":"C6_1","doc_id":"asce_ai_readiness_memo_2025-12-20","object_type":"child","parent_id":"P6","title":"Ethics mapping: public welfare via applicability constraints","text":"Ethics alignment: Public welfare is supported by encoding applicability constraints and safety-relevant context into tokens, so AI retrieval can be constrained to appropriate use conditions and reduce unsafe misapplication.","metadata":{"section":"6","type":"ethics_mapping","ethics_id":"i","authority":"ASCE_memo"}}
{"id":"C6_2","doc_id":"asce_ai_readiness_memo_2025-12-20","object_type":"child","parent_id":"P6","title":"Ethics mapping: truthfulness via provenance and versioning","text":"Ethics alignment: Truthful and objective use is supported by embedding provenance and versioning signals in tokens, enabling users (and audits) to identify what authority, source, and version an AI relied upon.","metadata":{"section":"6","type":"ethics_mapping","ethics_id":"ii","authority":"ASCE_memo"}}
{"id":"C6_3","doc_id":"asce_ai_readiness_memo_2025-12-20","object_type":"child","parent_id":"P6","title":"Ethics mapping: faithful agency via identity binding","text":"Ethics alignment: Faithful agency is supported by identity binding (Soulbound Tokens) and accountability chains that connect outputs to responsible actors and governance rules, making responsibility machine-readable.","metadata":{"section":"6","type":"ethics_mapping","ethics_id":"iii","authority":"ASCE_memo"}}
{"id":"C6_4","doc_id":"asce_ai_readiness_memo_2025-12-20","object_type":"child","parent_id":"P6","title":"Ethics mapping: professional integrity via attribution and transparent reuse","text":"Ethics alignment: Professional integrity is supported by attribution metadata and transparent reuse rules so that AI-mediated outputs preserve credit to original sources and maintain clarity about authorized use.","metadata":{"section":"6","type":"ethics_mapping","ethics_id":"iv","authority":"ASCE_memo"}}

{"id":"P7","doc_id":"asce_ai_readiness_memo_2025-12-20","object_type":"parent","title":"7. Governance and Implementation Roadmap","text":"Section 7 proposes a phased roadmap under Board oversight: (1) Pilot a bounded corpus and produce tokenized objects + controlled embeddings; (2) Expand to education and additional publications; (3) Institutionalize governance, rights, attribution, and compensation policies; (4) Integrate by publishing governed APIs for approved agentic AI services and partners. It also notes governance must address authority labeling, supersession/deprecation, acceptable-use constraints, security controls, audit logging, and compiler-versus-source attribution.","metadata":{"section":"7","type":"section_parent","authority":"ASCE_memo"}}
{"id":"C7_1","doc_id":"asce_ai_readiness_memo_2025-12-20","object_type":"child","parent_id":"P7","title":"Roadmap Phase 1: Pilot","text":"Phase 1 (Pilot): Select a bounded corpus (e.g., specific standards, committee guidance, and a journal subset) and produce tokenized objects with controlled embedding generation and governed retrieval. The goal is to test governance, quality, and auditability in a limited scope.","metadata":{"section":"7","type":"roadmap_phase","phase":"1","authority":"ASCE_memo"}}
{"id":"C7_2","doc_id":"asce_ai_readiness_memo_2025-12-20","object_type":"child","parent_id":"P7","title":"Roadmap Phase 2: Expand","text":"Phase 2 (Expand): Extend tokenization and governed embeddings to additional ASCE content areas, including education and more publications, while maintaining authority labeling and version control.","metadata":{"section":"7","type":"roadmap_phase","phase":"2","authority":"ASCE_memo"}}
{"id":"C7_3","doc_id":"asce_ai_readiness_memo_2025-12-20","object_type":"child","parent_id":"P7","title":"Roadmap Phase 3: Institutionalize","text":"Phase 3 (Institutionalize): Adopt formal governance policies for rights, attribution, and compensation models; define approval workflows; and establish durable controls for how tokens are created, updated, and reused.","metadata":{"section":"7","type":"roadmap_phase","phase":"3","authority":"ASCE_memo"}}
{"id":"C7_4","doc_id":"asce_ai_readiness_memo_2025-12-20","object_type":"child","parent_id":"P7","title":"Roadmap Phase 4: Integrate","text":"Phase 4 (Integrate): Publish governed APIs and retrieval interfaces for approved agentic AI services and partner institutions so AI systems can retrieve ASCE-governed intelligence safely and audibly at scale.","metadata":{"section":"7","type":"roadmap_phase","phase":"4","authority":"ASCE_memo"}}
{"id":"C7_5","doc_id":"asce_ai_readiness_memo_2025-12-20","object_type":"child","parent_id":"P7","title":"Governance requirements checklist","text":"Governance must explicitly address: authority labeling (what is binding vs advisory), supersession and deprecation (what is current vs outdated), acceptable-use constraints, security controls, audit logging, and a clear compiler-versus-original-source attribution model.","metadata":{"section":"7","type":"governance_checklist","authority":"ASCE_memo"}}

{"id":"P8","doc_id":"asce_ai_readiness_memo_2025-12-20","object_type":"parent","title":"8. Recommendation","text":"Section 8 recommends the ASCE Board adopt an Intelligence Tokenization strategy and authorize a structured pilot program. The memo argues this positions ASCE to lead responsibly into the agentic AI era while safeguarding public trust, professional integrity, and the attributable (and potentially compensable) value of civil-engineering knowledge.","metadata":{"section":"8","type":"section_parent","authority":"ASCE_memo"}}
{"id":"C8_1","doc_id":"asce_ai_readiness_memo_2025-12-20","object_type":"child","parent_id":"P8","title":"Recommendation statement (action requested)","text":"Recommendation: ASCE should adopt an Intelligence Tokenization strategy and authorize a structured pilot to operationalize governed retrieval, auditability, attribution, and ethics-aligned AI use of civil-engineering intelligence.","metadata":{"section":"8","type":"recommendation","authority":"ASCE_memo"}}
